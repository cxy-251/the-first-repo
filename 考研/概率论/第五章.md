###### 第五章 大数定律和中心极限定理
> 切比雪夫不等式 $\Rightarrow$ 切比雪夫大数定律 $\Rightarrow$ 小概率事件原理
利德伯格-列维 中心极限定理 $\Rightarrow$ 棣莫弗-拉普拉斯 中心极限定理 $\Rightarrow$ 辛钦大数定律

###### 大数定律
###### 概率不等式
> $1.$ 马尔科夫不等式
设随机变量 $Y$ 的 $k$ 阶原点矩 $E\{\left|Y\right|^k\}<+\infty$，则对于任意的 $\varepsilon>0$，有
$P\{\left|Y\right|\geq \varepsilon\}\leq \frac{E\{\left|Y\right|^k\}}\varepsilon^k,k=1,2,\ldots$

> $2.$ 切比雪夫不等式
对马尔科夫不等式特别取 $k=2$，令 $Y=X-E(X),E\{\left|Y\right|^2\}=D(X)$ 存在，有切比雪夫不等式成立。
设随机变量 $X$ 的数学期望 $E(X)$ 和方差 $D(X)$ 都存在，则对于任意的 $\varepsilon>0$，有
$P\{\left|X-E(X)\right|\geq \varepsilon\}\leq\frac{D(X)}\varepsilon^2$ 或者 $P\{\left|X-E(X)\right|<\varepsilon\}\geq 1-\frac{D(X)}\varepsilon^2$
概率估计 方差性质 重复试验次数估计

***
###### 二、大数定律的定义
> $1.$ 依概率收敛
设 $X_n,n=1,2,\ldots$ 是一个随机变量序列，$X$ 是一个随机变量，若对于任意的 $\varepsilon>0$，有 $\lim\limits_{n\rightarrow\infty}P\{\left|X_n-X\right|\geq\varepsilon\}=0$ 或者 $\lim\limits_{n\rightarrow\infty}P\{\left|X_n-X\right|<\varepsilon\}=1$ 称随机变量序列 $\{X_n\}$ 依概率收敛于 $X$，记为 $X_n\stackrel{P}{\longrightarrow}X$ 或者 $\lim\limits_{n\rightarrow\infty}X_n=X,\ (P)$
$注1$ 在定义中，随机变量 $X$ 也可以是常数 $a$，称随机变量序列 $\{X_n\}$ 依概率收敛域常数 $a$。
$注2$ 随机变量序列依概率收敛不同于微积分中数列或函数列的收敛性。
随机变量序列 $\{X_n\}$ 依概率收敛于 $X$，指当 $n$ 足够大时，有足够大的概率保证 $X_n$ 任意接近于 $X$，但 $X_n$ 仍然有可能与 $X$ 相差很大。

> $2.$ 大数定律定义
设 $X_n,n=1,2,\ldots$ 是随机变量序列，其数学期望都存在，若对于任意的 $\varepsilon>0$，有 $\lim\limits_{n\rightarrow}P\{\left|\frac 1n\sum\limits_{i=1}^nX_i-\frac 1n\sum\limits_{i=1}^nE(X_i)\right|<\varepsilon\}=1$ 称随机变量序列 $\{X_n\}$ 服从大数定律。
大数定律的概率意义：$\{X_k\},k=1,2,\cdots$ 的前 $n$ 项算术平均将紧密地聚集在其数学期望的附近。

***
###### 三、大数定律
###### 切比雪夫大数定律
> 设 $X_k,k=1,2\ldots$ 是相互独立的随机变量序列，其数学期望和方差都存在，且存在常数C，使得 $D(X_n)<C,k=1,2\ldots$ 则随机变量序列 $\{X_k\},k=1,2\ldots$ 服从大数定律。
证明 $E[\frac 1n\sum\limits_{i=1}nX_i]=\frac 1n\sum\limits_{i=1}^nE(X_i)$
$\quad E[\frac 1n\sum\limits_{i=1}^nX_i]=\frac 1n^2\sum\limits_{i=1}^nD(X_i)\leq\frac{nC}{n^2}=\frac Cn$
根据切比雪夫不等式，对于任意的 $\varepsilon>0$，有
$1\geq P\{\left|\frac 1n\sum\limits_{i=1}^nX_i-\frac 1n\sum_{i=1}^nE(X_i)\right|<\varepsilon\}$
$\quad\geq 1-\frac{D(\frac 1n\sum\limits_{i=1}^nX_i)}\varepsilon^2$
$\quad\geq 1-\frac C{n\varepsilon^2}\rightarrow 1,\ (as\ n\rightarrow\infty)$

> 推论 独立同分布大数定律
设 $X_k,k=1,2\ldots$ 是相互独立且同分布的随机变量序列，且 $E(X_k)=\mu,D(X_k)=\sigma^2,k=1,2,\ldots$ 则 $\{X_k\},k=1,2\ldots$ 服从大数定律，即对任意的 $\varepsilon>0$，有 $\lim\limits_{n\rightarrow\infty}P\{\left|\frac 1n\sum\limits_{k=1}^nX_k-\mu\right|<\varepsilon\}=1$
注 $1.$ 此定理是切比雪夫大数定律的一个推论。
$2.$ 为在实际应用中用将大量重复测量值的算术平均值作为精确值的估计提供了理论依据。

> 贝努里大数定律
设 $\frac mn$ 是 $n$ 次重复独立试验中事件 $A$ 发生的频率，$p$ 是事件 $A$ 在每次试验中发生的概率，则对任意的 $\forall\varepsilon>0$，有 $\lim\limits_{n\rightarrow\infty}P\{\left|\frac mn-p\right|<\varepsilon\}=1$
注 $1.$ 此定理是切比雪夫大数定律的推论。
$2.$ 此定理以严格的数学形式描述了频率的稳定性。
$3.$ <font color=009900>小概率事件原理</font> 概率很小的事件，在一次试验中几乎是不可能发生的，从而在实际中可看成不可能事件。

> 辛钦大数定律
设 $X_k,k=1,2\ldots$ 是相互独立同分布的随机变量序列，若 $X_k$ 的数学期望存在，则 $\{X_k\}$ 服从大数定律。

***
###### 中心极限定理
###### 一、中心极限定理的定义与意义
> 设随机变量 $X,X_1,X_2,\ldots$ 的分布函数分别为 $F(x),F1(x),F2(x),\ldots$，若极限式 $\lim\limits_{n\rightarrow\infty}F_n(x)=F(x)$ 在 $F(x)$ 的每一个连续点上都成立，称随机变量序列 $\{X_k\},k=1,2,\ldots$ 依分布收敛于 $X$。记为 $X_n\stackrel{L}{\longrightarrow}X$

> 中心极限定理 设随机变量序列 $\{X_k\},k=1,2,\ldots$ 相互独立，有有限数学期望和方差，若随机变量序列 $Y_n=\frac{\sum\limits_{k=1}^nX_k-\sum\limits_{k=1}^nE(X_k)}{\sqrt{\sum\limits_{k=1}^nD(X_k)}}$ 对 $Z\in\mathbb{R}$ 一致地有
$\lim\limits_{n\rightarrow\infty}P\{Y_n<z\}=\frac 1{\sqrt{2\pi}}\int_{-\infty}^ze^{-\frac 12y^2}dy=\Phi(z)$ 称随机变量序列 $\{X_k\}$ 服从中心极限定理。
$注1$ 随机变量序列 $\{X_k\}$ 服从中心极限定理，指其前 $n$ 项和 $\sum\limits_{k=1}^nX_k$ 的标准化随机变量依分布收敛于标准正态分布随机变量 $X$；
$注2$ 解释了现实中哪些随机变量服从或近似服从正态分布；

> 若随机变量序列 $\{X_k\},k=1,2,\ldots$ 服从中心极限定理，有
$\frac{\sum\limits_{k=1}^nX_k-\sum\limits_{k=1}^nE(X_k)}{\sqrt{\sum\limits_{k=1}^nD(X_k)}}\stackrel{L}{\rightarrow}X\sim N(0,1)\ as\ n\rightarrow\infty$ 故当 $n$ 足够大时，可以认为
$\frac{\sum\limits_{k=1}^nX_k-\sum\limits_{k=1}^nE(X_k)}{\sqrt{\sum\limits_{k=1}^nD(X_k)}}\sim N(0,1)$ 近似成立，或 $\sum\limits_{k=1}^nX_k\sim N(\sum\limits_{k=1}^nE(X_k),\sum\limits_{k=1}^nD(X_k))$ 近似成立。
许多相互独立的微小因素 $X_k$ 的叠加总和。

> $注3$ 给出了概率的近似计算公式。
若随机变量序列 $\{X_k\},k=1,2,\ldots$ 服从中心极限定理，则有
$P\{x_1\leq\frac{\sum\limits_{k=1}^nX_k-\sum\limits_{k=1}^nE(X_k)}{\sqrt{\sum\limits_{k=1}^nD(X_k)}}<x_2\}\approx\Phi(x_2)-\Phi(x_1)$

***
###### 二、中心极限定理
> 林德伯格-列维定理、独立同分布中心极限定理
设 $\{X_k\},k=1,2,\ldots$ 为相互独立，具有相同分布的随机变量序列，且 $E(X_k)=\mu,D(X_k)=\sigma^2$，则 $\{X_k\}$ 满足中心极限定理，即有
$\lim\limits_{n\rightarrow\infty}P\{\frac{\sum\limits_{k=1}^nX_k-n\mu}{\sqrt n\sigma}\leq x\}=\Phi(x)$

> 棣莫佛-拉普拉斯中心极限定理
设随机变量序列 $\{Y_n\},Y_n\sim B(n,p),n=1,2\ldots$，对于任意的实数 $x$ ，有
$\lim\limits_{n\rightarrow\infty}P\{\frac{Y_n-np}{\sqrt{np(1-p)}}\leq x\}=\Phi(x)$
证明 对于任意正整数 $n$，随机变量 $Y_n$ 可表示为 $Y_n=X_1+X_2+\ldots+X_n$
其中 $X_i\sim B(1,p)$，相互独立，并且 $E(X_i)=p,\ D(X_i)=p(1-p)$ 相互独立同分布的随机变量序列 $\{X_i\},i=1,2,\ldots$ 满足中心极限定理。即有
$\lim\limits_{n\rightarrow\infty}P\{\frac{Y_n-np}{\sqrt{np(1-p)}}\leq x\}=\lim\limits_{n\rightarrow\infty}P\{\frac{\sum\limits_{k=1}^nX_k-\sum\limits_{k=1}^nE(X_k)}{\sqrt{\sum\limits_{k=1}^nD(X_k)}}\leq x\}=\Phi(x)$ 结论成立。
若 $X\sim B(n,p)$，对于足够大的 $n$，有 $P\{m_1<X\leq m_2\}=P\{\frac{m_1-np}{\sqrt{np(1-p)}}<\frac{X-np}{\sqrt{np(1-p)}}\leq\frac{m_2-np}{\sqrt{np(1-p)}}\}\approx\Phi(\frac{m_2-np}{\sqrt{np(1-p)}})-\Phi(\frac{m_1-np}{\sqrt{np(1-p)}})$


